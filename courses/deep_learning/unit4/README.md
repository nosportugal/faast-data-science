# Unit 4: Optimizing Neural Nets

Congrats! You've trained your neural network for sentiment classification. Now it starts to get interesting &mdash; you will learn all the tips and tricks for optimizing your neural net and taking it to the next level!

## Content

Watch the following content. We list some of the main concepts on each of the units, if you feel comfortable with them you can skip that lesson. If not, watch it an do the quizzes at the end of each sub-unit.

- [Deep Learning Fundamentals: Units 6](https://lightning.ai/courses/deep-learning-fundamentals/unit-6-overview-essential-deep-learning-tips-tricks/) (â‰ˆ100 minutes)
  - Skip 6.5 unit which uses a deprecated library for hyperparameter tuning.

 ## Assignment
1. Start from your code from the previous unit and experiment with the hyper-parameters and architecture of your neural network.
2. Push the changes to your repo and submit at least one new submission to Kaggle. If possible try to find hyper-parameters that (even if slightly) improve your baseline score. 

## Extra Materials
- [Building makemore Part 3: Activations & Gradients, BatchNorm
](https://www.youtube.com/watch?v=P6sfmUTpUmc&ab_channel=AndrejKarpathy). The third part, just as good as the previous, dives into some of the modern innovations we go over this in unit such as Adam, Batch Normalisation, etc.
- [Google's Tuning Playbook](https://github.com/google-research/tuning_playbook) is the go to reference for optimising neural nets.
- [DeepLearning.AI Optimisation Notes](https://www.deeplearning.ai/ai-notes/optimization/index.html) is a good interactive reference for improving your intuition on the optimisation of Neural Networks.
